m
m <- leaflet(data.frame(lat = lat, lon = lon, mag = mag)) %>%
addTiles() %>%
addCircles(color = ~pal(mag))
m
addLegend(pal = pal, values = ~mag)
m <- leaflet(data.frame(lat = lat, lon = lon, mag = mag)) %>%
addTiles() %>%
addCircles(color = ~pal(mag)) %>%
addLegend(pal = pal, values = ~mag)
m
mag
summary(mag)
library(RSQLite)
install.packages("RSQLite")
library(DBI)
# Create an ephemeral in-memory RSQLite database
con <- dbConnect(RSQLite::SQLite(), ":memory:")
dbListTables(con)
# Create an ephemeral in-memory RSQLite database
con <- dbConnect(RSQLite::SQLite(), ":memory:")
RSQLite::SQLite()
# Create an ephemeral in-memory RSQLite database
con = dbConnect(RSQLite::SQLite(), ":memory:")
dbConnect()
# Create an ephemeral in-memory RSQLite database
con = dbConnect(RSQLite::SQLite(), "../Documents/GitHub/donnees/Chinook/Chinook_Sqlite.sqlite")
install.packages("DBI")
install.packages("DBI")
library(DBI)
# Create an ephemeral in-memory RSQLite database
con = dbConnect(RSQLite::SQLite(), "../Documents/GitHub/donnees/Chinook/Chinook_Sqlite.sqlite")
library(RSQLite)
R.version.string
library(installr)
updateR()
20*300*300000
20*300*300000*100
20*300*300000*100 / 1000000
20*300*300000*6
20*300*300000*6 / 1000
20*300*300000*6 / 1000000
20*300*300000*6 / 1000000000
4*4+9*4+5*1
20*300*300000*6 / 1000000000 * 57
?rep
d = data.frame(
annee = rep(c(2018, 2019), each = 12),
mois = rep(1:12, 2),
valeur = 101:124
)
d
library(sqldf)
install.packages("sqldf")
sqldf("
SELECT R1.annee, R1.mois,
SUM(R2.valeur) / SUM(R2.valeur) AS Ratio
FROM d R1
INNER JOIN d R2 ON ((R1.annee * 12 + R1.mois) - (R2.annee * 12 + R2.mois)) <= 3
GROUP BY R1.annee, R1.mois
ORDER BY R1.annee, R1.mois;
")
library(sqldf)
sqldf("
SELECT R1.annee, R1.mois,
SUM(R2.valeur) / SUM(R2.valeur) AS Ratio
FROM d R1
INNER JOIN d R2 ON ((R1.annee * 12 + R1.mois) - (R2.annee * 12 + R2.mois)) <= 3
GROUP BY R1.annee, R1.mois
ORDER BY R1.annee, R1.mois;
")
262000*.4
nb_BTn = 155000*.87
nb_placesIUT * quota_IUT + nb_placesBTS * quota_BTS
nb_BTn = 155000*.88
nb_placesIUT = 116000
nb_placesBTS = 262000
quota_IUT = .5
quota_BTS = .4
nb_placesIUT * quota_IUT + nb_placesBTS * quota_BTS
nb_BTn = 155000*.88
nb_placesIUT = 63000
nb_placesBTS = 262000
quota_IUT = .5
quota_BTS = .4
nb_placesIUT * quota_IUT + nb_placesBTS * quota_BTS
nb_BTn
library(readr)
WGI <- read_csv("GitHub/cours-2019-2020/lp-iot--python-ds/WGI.csv")
View(WGI)
library(FactoMineR)
pincomp(WGI)
princomp(WGI)
princomp(WGI[,3:8])
princomp(na.omit(WGI[,3:8]))
dim(WGI)
pr = princomp(na.omit(WGI[,3:8]))
pr$loadings
pr$scale
pr$sdev
pr$sdev*2
pr$sdev**2
pr$sdev**2*(210/209)
(pr$sdev*(210/209))**2
(pr$sdev*(209/210))**2
(pr$sdev*(211/210))**2
pr$sdev**2*(211/210)
knitr::opts_chunk$set(echo = TRUE)
m_resto = mongo(url = "mongodb://193.51.82.104:2343",
db = "test",
collection = "restaurants")
library(mongolite)
m_resto = mongo(url = "mongodb://193.51.82.104:2343",
db = "test",
collection = "restaurants")
m_resto$count()
m_resto = mongo(url = "mongodb://193.51.82.104:2343",
db = "test",
collection = "restaurants")
m_resto$count()
m_resto$count()
m_resto$count()
m_resto$find(
query = '{ "name": "Bareburger" }',
fields = '{ "_id": 0, "adress.street": 1, "borough": 1 }'
)
m_resto$find(limit = 1)
m_resto$find(
query = '{ "name": "Bareburger" }',
fields = '{ "_id": 0, "adress.street": 1, "borough": 1 }'
)
m_resto$find(
query = '{ "name": "Bareburger" }'
)
m_resto$find(
query = '{ "name": "Bareburger" }'
)
m_resto$find(
query = '{ "name": "Bareburger" }',
fields = '{ "_id": 0, "adress.street": 1, "borough": 1 }'
)
m_resto$find(
query = '{ "name": "Bareburger" }',
fields = '{ "_id": 0, "address.street": 1, "borough": 1 }'
)
m_resto$aggregate(
'[
{ "$group": { "_id": "$name", "NbRestos": { "$sum": 1 }}},
{ "$sort": { "NbRestos": -1 }},
{ "$limit": 3 }
]'
)
mobiliers = mongo(url = "mongodb://193.51.82.104:2343",
db = "horodateurs",
collection = "mobiliers")
transactions = mongo(url = "mongodb://193.51.82.104:2343",
db = "horodateurs",
collection = "transactions_small")
transactions$find(fields = '{ "montant carte": 1, "durée payée (h)": 1, "_id": 0}')
dfHisto = transactions$find(fields = '{ "montant carte": 1, "durée payée (h)": 1, "_id": 0}')
ggplot(dfHisto, aes(`montant carte`)) +
geom_histogram()
library(ggplot2)
ggplot(dfHisto, aes(`montant carte`)) +
geom_histogram()
ggplot(dfHisto, aes(`durée payée (h)`)) +
geom_histogram()
names(dfHisto)
encoding()
Encoding()
Encoding
ggplot(dfHisto, aes(`durée payée (h)`)) +
geom_histogram()
ggplot(dfHisto, aes(`durÃ©e payÃ©e (h)`)) +
geom_histogram()
mobiliers = mongo(url = "mongodb://193.51.82.104:2343",
db = "horodateurs",
collection = "mobiliers")
library(mongolite)
mobiliers = mongo(url = "mongodb://193.51.82.104:2343",
db = "horodateurs",
collection = "mobiliers")
mobiliers = mongo(db = "test", collection = "restaurants")
mobiliers$count()
gr1 = mongo(db = "test", collection = "grades")
gr2 = mongo(url = "mongodb://193.51.82.104:2343",
db = "test",
collection = "grade")
gr1$count()
gr2$count()
gr2 = mongo(url = "mongodb://193.51.82.104:2343",
db = "test",
collection = "grades")
gr2$count()
gr1$insert(gr2$find())
install.packages("Rlinkedin")
library(Rlinkedin)
library(tidyverse)
# To use the default API and Secret Key for the Rlinkedin package:
in.auth <- inOAuth()
# To use the default API and Secret Key for the Rlinkedin package:
in.auth <- inOAuth()
library(jsonlite)
toJSON(iris)
lapply(iris, function(e) { print(e) })
list(iris)
lapply(iris, function(e) { e })
toJSON(lapply(iris, function(e) { e }))
?write_json
write_json(lapply(iris, function(e) { e }), path = "GitHub/explore-data/data/iris.json")
write_json(iris, path = "GitHub/explore-data/data/iris.json")
write_json(ggplot2::diamonds, path = "GitHub/explore-data/data/diamonds.json")
library(jsonlite)
library(tidyverse)
write_json(ggplot2::diamonds, path = "GitHub/explore-data/data/diamonds.json")
write_json(LifeCycleSavings, path = "GitHub/explore-data/data/LifeCycleSavings.json")
?LifeCycleSavings
LifeCycleSavings
write_json(LifeCycleSavings %>% rownames_to_column("country"), path = "GitHub/explore-data/data/LifeCycleSavings.json")
write_json(diamonds, path = "GitHub/explore-data/data/diamonds.json")
library(jsonlite)
library(tidyverse)
write_json(diamonds, path = "GitHub/explore-data/data/diamonds.json")
#---------------------------------------------------------------------------------
#   readCovid.data.R
#   Marc Lavielle, Xpop, Inria Saclay & Ecole Polytechnique
#   2020, March 3
#---------------------------------------------------------------------------------
rm(list=ls())
# -- required libraries
library(reshape2)
library(dplyr)
library(ggplot2)
theme_set(theme_bw())
#-------------  OPTIONS ---------------------------------------------------------
# -- path to the directory where the data is being stored
setwd("C:/Divers/CNAM/2019/Covid")
# -- download.data = TRUE is necessary only once per day. Then, set it to FALSE
download.data <- TRUE
# -- selected countries
#country.plot <- c("Italy", "Spain", "France", "Germany", "Netherlands", "United Kingdom", "Switzerland", "SouthKorea","Japan","Singapore","China Hong Kong" )
country.plot <- c("France")
# -- set disp.country = TRUE to display the complete list of countries/states at the end of the run
disp.country <- TRUE
# -- selected series to plot among ("Confirmed", "Deaths", "Recovered")
data.plot <- c("Confirmed", "Deaths")
#------------------------------------------------------------------------------------
#----   load the data
f <- paste0(data.plot,".csv")
if (download.data) {
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv",
destfile = "Confirmed.csv")
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv",
destfile = "Deaths.csv")
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv",
destfile = "Recovered.csv")
}
nf <- length(f)
d <- list()
for (k in (1:nf)) {
# ---- read the data
dk <- read.csv(f[k])
# ---- remove unncessary columns
dk$Lat <- dk$Long <- NULL
# ---- reorder the rows
dk <- dk[order(dk[,2], dk[,1]),]
# ---- redefine country/region as single name
i1 <- which(as.character(dk[,1]) == as.character(dk[,2]))
dk[i1,1] <- ""
i2 <- which(!(dk[,1]==""))
fi2 <- paste(dk[i2,2],dk[i2,1])
i2 <- c(i2, grep("Korea", dk[,2]))
fi2 <- c(fi2, "SouthKorea")
levels(dk[,2]) <- c(levels(dk[,2]), fi2)
dk[i2,2] <- fi2
dk[,1]  <- NULL
names(dk)[1] <- "country"
# ---- remove some rows
i0 <- unique(c(grep("Princess",dk[,1]), grep(",",dk[,1]) ))
dk <- dk[-i0,]
# ---- reformat the data
n.day <- ncol(dk)-1
n.country <- nrow(dk)
dk <- melt(dk, id=list("country"), variable.name="date")
# ---- reformat the date and add the day
nk <- sub("X","",dk[['date']])
dk <- dk %>%
mutate(date=as.Date(nk,format = "%m.%d.%y")) %>%
arrange(country,date) %>%
mutate(day=rep(1:n.day, n.country))
dk$country <- droplevels(dk$country)
d[[k]] <- dk
}
c.select <- country.plot
d.select <- NULL
for (k in 1:nf) {
dks <- subset(d[[k]], country %in% c.select)
dks[['type']] <- as.factor(sub(".csv","", f[k]))
d.select <- rbind(d.select, dks)
}
d.select <- subset(d.select, value>0 )
d.select <- full_join(d.select,d.select  %>% group_by(country, type) %>% slice(min(which(value >= ifelse(type=="Confirmed",100,10)))), by=c("country","type"))%>%slice(which(value.x >= ifelse(type=="Confirmed",100,10)))
pl <- ggplot(data=d.select,aes(date.x-date.y, value.x, color=country)) + geom_line( size=0.5)  +  facet_wrap(~ type, scales="free_y", ncol=2)  + scale_y_log10("#") + scale_x_continuous(name="jours depuis le 100ème cas ou le 10ème décès")
print(pl)
#if (disp.country)
#  print(levels(dk$country))
getwd()
#---------------------------------------------------------------------------------
#   readCovid.data.R
#   Marc Lavielle, Xpop, Inria Saclay & Ecole Polytechnique
#   2020, March 3
#---------------------------------------------------------------------------------
rm(list=ls())
# -- required libraries
library(reshape2)
library(dplyr)
library(ggplot2)
theme_set(theme_bw())
#-------------  OPTIONS ---------------------------------------------------------
# -- path to the directory where the data is being stored
setwd("C:/Divers/CNAM/2019/Covid")
# -- download.data = TRUE is necessary only once per day. Then, set it to FALSE
download.data <- TRUE
# -- selected countries
country.plot <- c("Italy", "Spain", "France", "Germany", "Netherlands", "United Kingdom", "Switzerland", "SouthKorea","Japan","Singapore","China Hong Kong" )
#country.plot <- c("France")
# -- set disp.country = TRUE to display the complete list of countries/states at the end of the run
disp.country <- TRUE
# -- selected series to plot among ("Confirmed", "Deaths", "Recovered")
data.plot <- c("Confirmed", "Deaths")
#------------------------------------------------------------------------------------
#----   load the data
f <- paste0(data.plot,".csv")
if (download.data) {
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv",
destfile = "Confirmed.csv")
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv",
destfile = "Deaths.csv")
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv",
destfile = "Recovered.csv")
}
nf <- length(f)
d <- list()
for (k in (1:nf)) {
# ---- read the data
dk <- read.csv(f[k])
# ---- remove unncessary columns
dk$Lat <- dk$Long <- NULL
# ---- reorder the rows
dk <- dk[order(dk[,2], dk[,1]),]
# ---- redefine country/region as single name
i1 <- which(as.character(dk[,1]) == as.character(dk[,2]))
dk[i1,1] <- ""
i2 <- which(!(dk[,1]==""))
fi2 <- paste(dk[i2,2],dk[i2,1])
i2 <- c(i2, grep("Korea", dk[,2]))
fi2 <- c(fi2, "SouthKorea")
levels(dk[,2]) <- c(levels(dk[,2]), fi2)
dk[i2,2] <- fi2
dk[,1]  <- NULL
names(dk)[1] <- "country"
# ---- remove some rows
i0 <- unique(c(grep("Princess",dk[,1]), grep(",",dk[,1]) ))
dk <- dk[-i0,]
# ---- reformat the data
n.day <- ncol(dk)-1
n.country <- nrow(dk)
dk <- melt(dk, id=list("country"), variable.name="date")
# ---- reformat the date and add the day
nk <- sub("X","",dk[['date']])
dk <- dk %>%
mutate(date=as.Date(nk,format = "%m.%d.%y")) %>%
arrange(country,date) %>%
mutate(day=rep(1:n.day, n.country))
dk$country <- droplevels(dk$country)
d[[k]] <- dk
}
c.select <- country.plot
d.select <- NULL
for (k in 1:nf) {
dks <- subset(d[[k]], country %in% c.select)
dks[['type']] <- as.factor(sub(".csv","", f[k]))
d.select <- rbind(d.select, dks)
}
d.select <- subset(d.select, value>0 )
d.select <- full_join(d.select,d.select  %>% group_by(country, type) %>% slice(min(which(value >= ifelse(type=="Confirmed",100,10)))), by=c("country","type"))%>%slice(which(value.x >= ifelse(type=="Confirmed",100,10)))
pl <- ggplot(data=d.select,aes(date.x-date.y, value.x, color=country)) + geom_line( size=0.5)  +  facet_wrap(~ type, scales="free_y", ncol=2)  + scale_y_log10("#") + scale_x_continuous(name="jours depuis le 100ème cas ou le 10ème décès")
print(pl)
#if (disp.country)
#  print(levels(dk$country))
#---------------------------------------------------------------------------------
#   readCovid.data.R
#   Marc Lavielle, Xpop, Inria Saclay & Ecole Polytechnique
#   2020, March 3
#---------------------------------------------------------------------------------
rm(list=ls())
# -- required libraries
library(reshape2)
library(dplyr)
library(ggplot2)
theme_set(theme_bw())
#-------------  OPTIONS ---------------------------------------------------------
# -- path to the directory where the data is being stored
setwd("C:/Divers/CNAM/2019/Covid")
# -- download.data = TRUE is necessary only once per day. Then, set it to FALSE
download.data <- TRUE
# -- selected countries
country.plot <- c("Italy", "Spain", "France", "Germany", "Netherlands", "United Kingdom", "SouthKorea","Japan","China Hong Kong" )
#country.plot <- c("France")
# -- set disp.country = TRUE to display the complete list of countries/states at the end of the run
disp.country <- TRUE
# -- selected series to plot among ("Confirmed", "Deaths", "Recovered")
data.plot <- c("Confirmed", "Deaths")
#------------------------------------------------------------------------------------
#----   load the data
f <- paste0(data.plot,".csv")
if (download.data) {
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv",
destfile = "Confirmed.csv")
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv",
destfile = "Deaths.csv")
download.file("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv",
destfile = "Recovered.csv")
}
nf <- length(f)
d <- list()
for (k in (1:nf)) {
# ---- read the data
dk <- read.csv(f[k])
# ---- remove unncessary columns
dk$Lat <- dk$Long <- NULL
# ---- reorder the rows
dk <- dk[order(dk[,2], dk[,1]),]
# ---- redefine country/region as single name
i1 <- which(as.character(dk[,1]) == as.character(dk[,2]))
dk[i1,1] <- ""
i2 <- which(!(dk[,1]==""))
fi2 <- paste(dk[i2,2],dk[i2,1])
i2 <- c(i2, grep("Korea", dk[,2]))
fi2 <- c(fi2, "SouthKorea")
levels(dk[,2]) <- c(levels(dk[,2]), fi2)
dk[i2,2] <- fi2
dk[,1]  <- NULL
names(dk)[1] <- "country"
# ---- remove some rows
i0 <- unique(c(grep("Princess",dk[,1]), grep(",",dk[,1]) ))
dk <- dk[-i0,]
# ---- reformat the data
n.day <- ncol(dk)-1
n.country <- nrow(dk)
dk <- melt(dk, id=list("country"), variable.name="date")
# ---- reformat the date and add the day
nk <- sub("X","",dk[['date']])
dk <- dk %>%
mutate(date=as.Date(nk,format = "%m.%d.%y")) %>%
arrange(country,date) %>%
mutate(day=rep(1:n.day, n.country))
dk$country <- droplevels(dk$country)
d[[k]] <- dk
}
c.select <- country.plot
d.select <- NULL
for (k in 1:nf) {
dks <- subset(d[[k]], country %in% c.select)
dks[['type']] <- as.factor(sub(".csv","", f[k]))
d.select <- rbind(d.select, dks)
}
d.select <- subset(d.select, value>0 )
d.select <- full_join(d.select,d.select  %>% group_by(country, type) %>% slice(min(which(value >= ifelse(type=="Confirmed",100,10)))), by=c("country","type"))%>%slice(which(value.x >= ifelse(type=="Confirmed",100,10)))
pl <- ggplot(data=d.select,aes(date.x-date.y, value.x, color=country)) + geom_line( size=0.5)  +  facet_wrap(~ type, scales="free_y", ncol=2)  + scale_y_log10("#") + scale_x_continuous(name="jours depuis le 100ème cas ou le 10ème décès")
print(pl)
#if (disp.country)
#  print(levels(dk$country))
installr
library(installr)
updateR()
setd("../Documents/GitHub/cours-2019-2020/scimagojr/")
sewtd("../Documents/GitHub/cours-2019-2020/scimagojr/")
setwd("../Documents/GitHub/cours-2019-2020/scimagojr/")
library(tidyverse)
library(readxl)
fichier = dir()
liste = lapply(fichier, function(f) {
annee = str_split(str_split(f, " ")[[1]][2], "\\.")[[1]][1]
test = cbind(Year = as.numeric(annee), read_excel(f))
return(test)
})
View(liste[[1]])
res = Reduce(function(a, b) {
return(rbind(a, b))
}, liste)
??xls
library(xlsx)
write.xlsx(res, "../scimagojr.xlsx", sheetName = "All",
col.names = TRUE, row.names = FALSE, append = FALSE)
library(readxl)
fichier = dir()
liste = lapply(fichier, function(f) {
annee = str_split(str_split(f, " ")[[1]][2], "\\.")[[1]][1]
test = cbind(Year = as.numeric(annee), read_excel(f))
return(test)
})
res = Reduce(function(a, b) {
return(rbind(a, b))
}, liste)
library(xlsx)
write.xlsx(res, "../scimagojr.xlsx", sheetName = "All",
col.names = TRUE, row.names = FALSE, append = FALSE)
str(liste[[1]])
str(res)
write.xlsx(res, "../scimagojr.xlsx", sheetName = "All",
col.names = TRUE, row.names = FALSE, append = FALSE)
